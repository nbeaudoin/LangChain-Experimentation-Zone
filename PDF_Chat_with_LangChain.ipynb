{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJbKOZeLbz64X29V/I7Atr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nbeaudoin/LangChain-Experimentation-Zone/blob/main/PDF_Chat_with_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial Source: https://www.youtube.com/watch?v=ZzgUqFtxgXI&list=PL8motc6AQftk1Bs42EW45kwYbyJ4jOdiZ&index=18"
      ],
      "metadata": {
        "id": "W8M3fHDM6Kqc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dg2uxSZq6Ild",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0495fbd-1d4b-4e7b-8f5d-d879cbf088d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.5.1\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip -q install openai langchain\n",
        "!pip install python-dotenv\n",
        "!pip install tiktoken\n",
        "!pip install faiss-gpu\n",
        "\n",
        "# Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load variables from .env file\n",
        "load_dotenv('/content/drive/MyDrive/Projects/keys/secrets.json')\n",
        "\n",
        "# Use variables\n",
        "openai_api = os.getenv('OPENAI_API_KEY')\n",
        "huggingface_api = os.getenv('HUGGINGFACE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Chat PDF"
      ],
      "metadata": {
        "id": "-5uRHOmiS5Ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYmBFUtbLxmD",
        "outputId": "6dc35f03-2f8e-4827-8e89-d11a6d36225b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m174.1/232.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading in the PDF"
      ],
      "metadata": {
        "id": "ZRTZgeseTNjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# location of hte pdf file/files\n",
        "doc_reader = PdfReader('/content/drive/MyDrive/Projects/docs/impromptu-rh.pdf')"
      ],
      "metadata": {
        "id": "I39zaJswTDvB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_reader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0mTFp-WTWCQ",
        "outputId": "f6dbe142-4302-4491-e952-fe46dedb4147"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PyPDF2._reader.PdfReader at 0x7a5d7673bf10>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read the data from the file and put them into a variable called raw_text\n",
        "raw_text = ''\n",
        "for i, page in enumerate(doc_reader.pages):\n",
        "  text = page.extract_text()\n",
        "  if text:\n",
        "    raw_text += text"
      ],
      "metadata": {
        "id": "SSzNuNepTee_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(raw_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJFr4aqexuPF",
        "outputId": "7c072605-d379-42bc-a054-3abc900bb7f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "371090"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "UIA-BnK7x0Kk",
        "outputId": "fb6d87eb-2049-46d2-9647-5f8756bcc385"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Impromptu\\nAmplifying Our Humanity \\nThrough AI\\nBy Reid Hoffman  \\nwith GPT-4Impromptu: AmplIfyIng our '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Splitter\n",
        "\n",
        "This takes the text and splits it into chunks. The chunk size is characters not tokens"
      ],
      "metadata": {
        "id": "EfAK-eeFx6xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting up the text into smaller chunks for indexing\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 200,  #striding over the text\n",
        "    length_function = len\n",
        ")\n",
        "\n",
        "texts = text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "id": "OTlZUEOVx5Fk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psGwWjOJyQ_-",
        "outputId": "bb9d4951-d5d9-436b-d870-22f404cf2d2e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "466"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "oqife9ENyYli",
        "outputId": "acf22cb6-b63e-4c93-acc6-ab6c5f5082d9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Because, really, an AI book? When things are moving so \\nquickly? Even with a helpful AI on hand to speed the process, \\nany such book would be obsolete before we started to write it—\\nthat’s how fast the industry is moving.\\nSo I hemmed and hawed for a bit. And then I thought of a frame \\nthat pushed me into action.\\nThis didn’t have to be a comprehensive “book” book so much as \\na travelog, an informal exercise in exploration and discovery, \\nme (with GPT-4) choosing one path among many. A snapshot \\nmemorializing—in a subjective and decidedly not definitive \\nway—the AI future we were about to experience.\\nWhat would we see? What would impress us most? What would \\nwe learn about ourselves in the process? Well aware of the brief \\nhalf-life of this travelog’s relevance, I decided to press ahead.\\nA month later, at the end of November 2022, OpenAI released \\nChatGPT, a “conversational agent,” aka chatbot, a modified \\nversion of GPT-3.5 that they had fine-tuned through a process'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making the embeddings"
      ],
      "metadata": {
        "id": "TgLiKNH71ut6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the embeddings\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "PgjAIx2UyyBu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch = FAISS.from_texts(texts, embeddings)"
      ],
      "metadata": {
        "id": "XmcOr61r10IQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch.embedding_function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su0xmZ6N18a2",
        "outputId": "15344476-a2bf-4c1e-bedf-f4872f37d1d7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method OpenAIEmbeddings.embed_query of OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base='', openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='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', openai_organization='', allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=6, request_timeout=None, headers=None, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"how does GPT-4 change social media?\"\n",
        "docs = docsearch.similarity_search(query)"
      ],
      "metadata": {
        "id": "KfFmCqX72BJg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENCdmhRm2XTX",
        "outputId": "418f799c-497e-4dc2-d999-68fb1a2be1a7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDSRA9F92aS-",
        "outputId": "f7b5fe78-ef64-4d23-b206-461fe88169be"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='cian, GPT-4 and ChatGPT are not only able but also incredi-\\nbly willing to focus on whatever you want to talk about.4 This \\nsimple dynamic creates a highly personalized user experience. \\nAs an exchange with GPT-4 progresses, you are continuously \\nfine-tuning it to your specific preferences in that moment. \\nWhile this high degree of personalization informs whatever \\nyou’re using GPT-4 for, I believe it has special salience for the \\nnews media industry.\\nImagine a future where you go to a news website and use \\nqueries like these to define your experience there:\\n4  Provided it doesn’t violate the safety restrictions OpenAI has put on \\nthem.93Journalism\\n● Hey, Wall Street Journal, give me hundred-word summa-\\nries of your three most-read tech stories today.\\n● Hey, CNN, show me any climate change stories that hap-\\npened today involving policy-making.\\n● Hey, New York Times, can you create a counter-argument \\nto today’s Paul Krugman op-ed, using only news articles')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plain QA Chain"
      ],
      "metadata": {
        "id": "GQSyGzeAFhMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "8yIS5lV42ax2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_qa_chain(OpenAI(),\n",
        "                      chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "FwoBSwMVFoNT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the prompt\n",
        "chain.llm_chain.prompt.template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "fSdkSbIkFuL8",
        "outputId": "8b3422d3-8680-49c1-a423-7627901e1544"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"who are the authors of the book?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "p42gP9utFynr",
        "outputId": "eeaab18f-0ef6-4706-bcf1-12a9b60a5a87"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Reid Hoffman and Sam Altman.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"who are the authors of the book?\"\n",
        "query_02 = \"has it rained this week?\"\n",
        "docs = docsearch.similarity_search(query_02)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MUMbSd2CGJL6",
        "outputId": "0530148a-c227-4d8a-f0dc-37107ac4aefb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The authors of the book are Reid Abbasi and GPT-4.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"who is the booked authored by?\"\n",
        "docs = docsearch.similarity_search(query, k=4)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_21v3ZOxHCO4",
        "outputId": "786d3aa8-403d-461d-ab9a-320e2c48c753"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The book is authored by Reid Hoffman and GPT-4.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To get around context length, change the chain type\n",
        "chain = load_qa_chain(OpenAI(),\n",
        "                      chain_type=\"map_rerank\",\n",
        "                      return_intermediate_steps=True\n",
        "                      )\n",
        "\n",
        "query = \"who are openai?\"\n",
        "docs = docsearch.similarity_search(query, k=4)\n",
        "results = chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_oAjXT8HR66",
        "outputId": "5830162e-c315-45b6-8b94-9cfee279cd50"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:308: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intermediate_steps': [{'answer': ' OpenAI is an AI research and deployment company that was founded in 2015. It is known for its text-to-image generation tool DALL-E 2 and ChatGPT, as well as Midjourney and Stable Diffusion.',\n",
              "   'score': '80'},\n",
              "  {'answer': ' OpenAI is an organization founded in 2015 with the goal of developing technologies that put the power of AI directly into the hands of millions of people.',\n",
              "   'score': '100'},\n",
              "  {'answer': ' OpenAI is an AI research and development company based in San Francisco, California.',\n",
              "   'score': '90'},\n",
              "  {'answer': ' OpenAI is a research company focused on developing artificial intelligence (AI) technology.',\n",
              "   'score': '100'}],\n",
              " 'output_text': ' OpenAI is an organization founded in 2015 with the goal of developing technologies that put the power of AI directly into the hands of millions of people.'}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results['output_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qWeV1av_H58X",
        "outputId": "5cd1647c-3777-4a0f-be58-f5cee2821ac1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' OpenAI is an organization founded in 2015 with the goal of developing technologies that put the power of AI directly into the hands of millions of people.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results['intermediate_steps']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh_WxwsKIWWT",
        "outputId": "517ef0a4-562f-4484-b9c1-078c86bb09f2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'answer': ' OpenAI is an AI research and deployment company that was founded in 2015. It is known for its text-to-image generation tool DALL-E 2 and ChatGPT, as well as Midjourney and Stable Diffusion.',\n",
              "  'score': '80'},\n",
              " {'answer': ' OpenAI is an organization founded in 2015 with the goal of developing technologies that put the power of AI directly into the hands of millions of people.',\n",
              "  'score': '100'},\n",
              " {'answer': ' OpenAI is an AI research and development company based in San Francisco, California.',\n",
              "  'score': '90'},\n",
              " {'answer': ' OpenAI is a research company focused on developing artificial intelligence (AI) technology.',\n",
              "  'score': '100'}]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the prompt\n",
        "chain.llm_chain.prompt.template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "nZE8i1BwIYXZ",
        "outputId": "8fccf64b-ca99-4d5f-d596-cd6cc926c70e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nIn addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\\n\\nQuestion: [question here]\\nHelpful Answer: [answer here]\\nScore: [score between 0 and 100]\\n\\nHow to determine the score:\\n- Higher is a better answer\\n- Better responds fully to the asked question, with sufficient level of detail\\n- If you do not know the answer based on the context, that should be a score of 0\\n- Don't be overconfident!\\n\\nExample #1\\n\\nContext:\\n---------\\nApples are red\\n---------\\nQuestion: what color are apples?\\nHelpful Answer: red\\nScore: 100\\n\\nExample #2\\n\\nContext:\\n---------\\nit was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\\n---------\\nQuestion: what type was the car?\\nHelpful Answer: a sports car or an suv\\nScore: 60\\n\\nExample #3\\n\\nContext:\\n---------\\nPears are either red or orange\\n---------\\nQuestion: what color are apples?\\nHelpful Answer: This document does not answer the question\\nScore: 0\\n\\nBegin!\\n\\nContext:\\n---------\\n{context}\\n---------\\nQuestion: {question}\\nHelpful Answer:\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RetrievalQA\n",
        "\n",
        "RetrievalQA chain uses load_qa_chain and combines it with the a retriever (in our case the FAISS index)"
      ],
      "metadata": {
        "id": "_i_sBHTRI4l9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# set up FAISS as a generic retriever\n",
        "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
        "\n",
        "# create the chain to answer questions\n",
        "rqa = RetrievalQA.from_chain_type(llm=OpenAI(),\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True)\n"
      ],
      "metadata": {
        "id": "Zi6zbB1AIo_N"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rqa(\"What is OpenAI?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1txp9291JdC9",
        "outputId": "fb1934e9-392a-4505-89b0-ef3cfb9fe1cc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'What is OpenAI?',\n",
              " 'result': ' OpenAI is a research organization that develops and shares artificial intelligence tools for the benefit of humanity. It does not claim any ownership or rights over the content that its tools produce or help produce.',\n",
              " 'source_documents': [Document(page_content='ing to their own lives however they best saw fit.\\nEspecially in the realm of work, I realized, AI deployed in this \\nway could give individuals incredibly versatile new tools to \\napply to their careers, professional development, and economic \\nautonomy. So when I had a chance to become one of OpenAI’s \\ninitial funders in 2015, I took it. The vision of AI that it was \\nplanning to pursue felt like a natural extension of the goals that \\nhad inspired me to co-found LinkedIn in 2002.\\nWhen OpenAI released its text-to-image generation tool, \\nDALL-E 2, in April 2022, and then followed up six months later \\nwith ChatGPT, the organization’s mission to give millions of \\nusers hands-on access to these remarkable AI tools started to \\nplay out in a big way.\\nNow, thanks to these tools and others like Midjourney and \\nStable Diffusion, a new kind of opt-in, user-driven, and very \\nvisible AI usage suddenly exists. Users share their outputs, \\ntechniques, experiences, and opinions on Twitter, YouTube,'),\n",
              "  Document(page_content='sion from Congress.\\nWanting to protect society from bad tech outcomes is not a new \\nphenomenon, of course. In fact, it’s exactly this sentiment that \\nled OpenAI’s founders to create their organization in 2015.\\nSo what’s the most effective and inclusive way to achieve good \\noutcomes for society in the long term?\\nIn recent years, the predominant critique of AI is that it is some-\\nthing that has largely been happening to individuals rather \\nthan for them—an under-the-radar force deployed by Big Tech \\nwithout much public knowledge, much less consent, via tech -\\nnologies like facial recognition and algorithmic decision-mak-\\ning on home loans, job applicant screening, social media rec-\\nommendations, and more.\\nA founding goal of OpenAI was to develop technologies that put \\nthe power of AI directly into the hands of millions of people. \\nIn this way, AI might function as a decentralized, personally \\nempowering force, rather than a top-down, totalizing one.'),\n",
              "  Document(page_content='Because, really, an AI book? When things are moving so \\nquickly? Even with a helpful AI on hand to speed the process, \\nany such book would be obsolete before we started to write it—\\nthat’s how fast the industry is moving.\\nSo I hemmed and hawed for a bit. And then I thought of a frame \\nthat pushed me into action.\\nThis didn’t have to be a comprehensive “book” book so much as \\na travelog, an informal exercise in exploration and discovery, \\nme (with GPT-4) choosing one path among many. A snapshot \\nmemorializing—in a subjective and decidedly not definitive \\nway—the AI future we were about to experience.\\nWhat would we see? What would impress us most? What would \\nwe learn about ourselves in the process? Well aware of the brief \\nhalf-life of this travelog’s relevance, I decided to press ahead.\\nA month later, at the end of November 2022, OpenAI released \\nChatGPT, a “conversational agent,” aka chatbot, a modified \\nversion of GPT-3.5 that they had fine-tuned through a process'),\n",
              "  Document(page_content='Clearly, I see AI as a transformative force in both my profes -\\nsional and philanthropic work. I anticipate that it will help me \\nbe more efficient, productive, and creative in a variety of ways. \\nI also see the potential for AI to amplify the impact of the orga-\\nnizations I support by helping them connect with a wider audi-\\nence, streamline operations, and identify new opportunities.\\nAs an investor, I’m keenly aware of the potential for AI-pow-\\nered companies to achieve tremendous success, and as the \\nworld increasingly embraces AI, I’m positioning myself and my \\norganizations to be at the forefront of this transformation.\\nI hope you will do the same for you and yours.WHEN AI MAKES THINGS UP  \\n(“HALLUCINATIONS”)\\nWhen OpenAI introduced ChatGPT to the world via a \\n“research preview” on November 30, 2022, a company blog \\npost warned that “ChatGPT sometimes writes plausible-sound -\\ning but incorrect or nonsensical answers.”\\nIn just five days, one million people signed up to give ChatGPT'),\n",
              "  Document(page_content='A month later, at the end of November 2022, OpenAI released \\nChatGPT, a “conversational agent,” aka chatbot, a modified \\nversion of GPT-3.5 that they had fine-tuned through a process \\ncalled Reinforcement Learning through Human Feedback \\n(RLHF) to enable more flowing, human-like conversations with \\nits human users. Five days later, ChatGPT had more than a \\nmillion registered users. \\nIn late January 2023, Microsoft1—which had invested $1 billion \\nin OpenAI in 2019—announced that it would be investing $10 \\nbillion more in the company. It soon unveiled a new version of \\nits search engine Bing, with a variation of ChatGPT built into it.\\n1 I sit on Microsoft’s Board of Directors. 10Impromptu: Amplifying Our Humanity Through AI\\nBy the start of February 2023, OpenAI said ChatGPT had \\none hundred million monthly active users, making it the fast-\\nest-growing consumer internet app ever. Along with that \\ntorrent of user interest, there were news stories of the new Bing'),\n",
              "  Document(page_content='feedback loop of rapid learning and careful iteration.”\\nIn other words, the approach OpenAI and other AI developers \\nare now employing exists as a healthy and more democratic \\nalternative to the surreptitious, highly centralized, and unilat-\\nerally imposed development paradigm that many feared would \\nserve as the only template for AI development.\\nAnd yet, now that individuals are getting a chance to materi-\\nally participate in the development of new AI technologies, a \\nsense of alarm is growing. As mentioned earlier, very soon after \\nChatGPT’s release, administrators of K–12 schools in New York \\nCity, Oakland, and Seattle, to name just a few cities, banned its \\nuse. In addition, calls for government intervention have been \\nticking upwards. A few recent examples:\\n“As one of just three members of Congress with a computer \\nscience degree, I am enthralled by AI and excited about the \\nincredible ways it will continue to advance society. And as a'),\n",
              "  Document(page_content='OpenAI had created a tool that became “intelligent” enough \\nto productively assist you in many different environments, in \\nmany different ways.\\nMuch of what we do as modern people—at work and beyond—\\nis to process information and generate action. GPT-4 will mas-\\nsively speed your ability to do these things, and with greater \\nbreadth and scope. Within a few years, this copilot will fall \\nsomewhere between useful and essential to most profession -\\nals and many other sorts of workers. Without GPT-4, they’ll 6Impromptu: Amplifying Our Humanity Through AI\\nbe slower, less comprehensive, and working at a great dis-\\nadvantage. \\nFor example, GPT-4 is a research tool you can use to quickly get \\nan overview on supply chain management issues in the COVID-\\n19 era—or to plan a week-long vacation itinerary to Patagonia \\nthat takes into account that you’re a vegan who enjoys moder-\\nately challenging hikes. \\nAlong with enabling a new kind of highly contextualized search,'),\n",
              "  Document(page_content='policy level too.\\nLet’s get back to a question we put a pin in earlier: who owns \\nthis stuff?\\nReid: If someone uses this GPT to help generate story \\nideas, and then she uses one of those ideas to create \\na screenplay and sells that screenplay, does OpenAI \\nhave any claim on the money from the sale? (250 \\nwords or less) (make prose more lively and less wooden \\nthan usual)\\nGPT-4:  The short answer is: no. OpenAI is a research \\norganization that develops and shares artificial intelli-\\ngence tools for the benefit of humanity. It does not claim \\nany ownership or rights over the content that its tools \\nproduce or help produce. You are free to use the GPT \\ntool as a source of inspiration, but you are responsible for \\nyour own originality, quality, and legality of your work.\\nThe long answer is: it depends. OpenAI has a Terms of \\nUse and an Acceptable Use Policy that govern how you \\ncan use its tools and services. You have to agree to these \\nterms when you access the GPT tool, and they include'),\n",
              "  Document(page_content='Stable Diffusion, a new kind of opt-in, user-driven, and very \\nvisible AI usage suddenly exists. Users share their outputs, \\ntechniques, experiences, and opinions on Twitter, YouTube, \\nGithub, Discord, and more. Diverse viewpoints from around \\nthe world, informed by hands-on usage, shape this discourse, \\nwhich is always spirited, often fractious, and, to my mind, \\nhighly productive.\\nMillions of people, including many whose main goal is to find \\nflaws in these systems, are getting a shot to shape the further \\nevolution of AI through their usage, feedback, and critiques. As 233Conclusion: At the Crossroads of the 21st Century\\nOpenAI co-founder and CEO Sam Altman exclaimed in a recent \\npost on OpenAI’s website, “We currently believe the best way to \\nsuccessfully navigate AI deployment challenges is with a tight \\nfeedback loop of rapid learning and careful iteration.”\\nIn other words, the approach OpenAI and other AI developers \\nare now employing exists as a healthy and more democratic'),\n",
              "  Document(page_content='strikingly different from how AI has generally been portrayed \\nover the years. Granted, many of those portrayals have come \\nfrom Hollywood, science fiction, and journalism, rather than \\nfrom technologists working to make highly intelligent machines \\na reality. \\nThat said, many technologists and high-tech organizations, \\nincluding OpenAI, do in fact have their sights set on a much \\nmore ambitious form of AI: machines that can operate com-\\npletely autonomously; machines that are capable of human-like \\ncommon-sense reasoning and self-awareness.\\nGPT-4 is not that, at least not yet. For now, it is neither \\nall-knowing nor infallible. \\nInstead, it is, in its own words, a “tool” that requires human \\n“caution, curiosity, and responsibility” to operate most \\nproductively.\\nI think this is the correct perspective. If you simply let GPT-4 do \\nall the work, with no human oversight or engagement, it’s a less \\npowerful tool. It’s still a very human tool, of course, because')]}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How does Gen AI impact journalism?\"\n",
        "rqa(query)['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lokpLnvUJgOY",
        "outputId": "7b6a2982-dd46-430b-bf8b-e4388af1b808"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Gen AI can help journalists work more productively and effectively, as well as provide opportunities for novel ways of finding and telling stories. Additionally, it provides an opportunity to create a more visible culture of informational transparency and accountability.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How is GPT-4 different than GPT-3?\"\n",
        "rqa(query)['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "oiuKRUOzJ8yb",
        "outputId": "05d91027-9563-43e7-ff31-f6fbd3e78e60"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' GPT-4 has been demonstrated to have greater proficiency than GPT-3, including being able to generate better lightbulb jokes, prose of all kinds, emails, poetry, essays, summaries of documents, translations of languages, and computer code. Additionally, GPT-4 is designed to focus on whatever the user wants to talk about, creating a personalized user experience.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who is Nicholas Beaudoin?\"\n",
        "rqa(query)['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FapnUyTOKcQZ",
        "outputId": "600101cd-ce04-4620-a74f-c9a873d6ab3b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" I don't know.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lOObmobVK_nW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}